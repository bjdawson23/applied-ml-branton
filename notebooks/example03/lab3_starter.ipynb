{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3 â€“ Predicting a Categorical Target and Evaluating Performance\n",
    "\n",
    "In this lab, we are going to use a model to predict the gender (male = 0 or male = 1) of people from the Howell dataset. We will train multiple models, evaluate performance using key metrics, and create visualizations to interpret the results.\n",
    "\n",
    "Start with your work on Lab 2. We trim that notebook down and do our training and analysis.\n",
    "\n",
    "We will:\n",
    "1. Prepare the data\n",
    "2. Train 3 models: Decision Tree, Support Vector Machine (SVM), and a Neural Net (NN)\n",
    "3. Get model performance on train and test sets\n",
    "4. Create appropriate graphs\n",
    "\n",
    "NOTE: We will just work with the adults since there is a nice break in the data that is not there for the children.\n",
    "\n",
    "You should see train/test counts of approximately:\n",
    "Train    size:        276    Test    size:        70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1. Load and Inspect the Data\n",
    "1.1 Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Howell.csv from the same folder as this file\n",
    "\n",
    "howell_full = pd.read_csv(\"Howell.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "In our case we have no missing data, so the code here is just for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2. Data Exploration and Preparation\n",
    "\n",
    "2.1 Create new features\n",
    "\n",
    "    Compute BMI from height and weight\n",
    "    Create BMI category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3. Feature Selection and Justification\n",
    "3.1 Choose features and target\n",
    "\n",
    "First:\n",
    "\n",
    "    input features: Height,\n",
    "    target: Gender\n",
    "\n",
    "Second:\n",
    "\n",
    "    input features:  Weight,\n",
    "    target: Gender\n",
    "\n",
    "Third:\n",
    "\n",
    "    input features: Height, Weight\n",
    "    target: Gender\n",
    "\n",
    " \n",
    "\n",
    "Justify your selections\n",
    "\n",
    "    Height and weight are likely to show patterns based on gender.\n",
    "    Age could contribute to secondary patterns. By restricting our data to adults, we help mitigate some of this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define X (features) and y (target)\n",
    "\n",
    "Comment out or uncomment the appropriate feature set before splitting the data. This code is set to run Case 1 - the inputs are just height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "\n",
    "     Why did you choose these features?\n",
    "     How might they impact predictions or accuracy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4. Train a Classification Model (Decision Tree)\n",
    " \n",
    "4.1 Split the Data\n",
    "\n",
    "Split the data into training and test sets using train_test_split (or StratifiedShuffleSplit if class imbalance is an issue).\n",
    "\n",
    "Use StratifiedShuffleSplit to ensure even distribution of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train Model (Decision Tree)\n",
    "\n",
    "    Create and train a decision tree model with no random initializer argument.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluate Model Performance\n",
    "\n",
    "Evaluate model performance on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance on test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Report Confusion Matrix (as a heatmap)\n",
    "\n",
    "Plot a confusion matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Report Decision Tree Plot\n",
    "\n",
    "Plot the DT model. We give the plotter the names of the features and the names of the categories for the target. Save the image so we can use it in other places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for All 3 Cases\n",
    "\n",
    "Try this for the 3 different cases: 1) using height as the only input  2) using weight as the only input and 3) using height and weight together as inputs. \n",
    "\n",
    "For each different case, redefine the input features in Section 3 (comment out the old case inputs X and target y and uncomment the new case inputs X and target y), then re-run Sections 4 and 5 for each case. Record your results in a Markdown table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 4:\n",
    "\n",
    "    How well did the models perform?\n",
    "    Are there any surprising results?\n",
    "    Which worked better: just height, just weight, or using both together? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5. Compare Alternative Models (SVC, NN)\n",
    "\n",
    " \n",
    "5.1 Train Support Vector Classifier (SVC) Model\n",
    "\n",
    "Train an SVM model using height and weight. Even though we suspect that it is better to just use height as the input, we will use both height and weight for the SVC since that will give a better visualization for the support vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and evaluate SVC model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the support vectors.\n",
    "We will add a third scatter plot showing the support vectors. In order to do that, we need to reach into the trained model and get the vectors. Then we can plot the points with a black cross.\n",
    "This is a special shortcut for constructing a list in python called a list comprehension.\n",
    "The square brackets let us know we are building up a list. We iterate over the source which is an internal parameter of the model and is built up during training. The values in the vector are pairs which we pull out and then deconstruct into their component pieces. (x,y). List comprehensions are one of the nice features of python. Suppose I wanted a list of cubes... The code [x*x for x in range(1,6)] will build the list [1, 4, 9, 25]\n",
    "\n",
    "We now have two lists of data that we can hand over to matplotlib.\n",
    "We need to plot the new data and we will adjust the color of the points. Changes and the new line are marked in red.\n",
    "\n",
    "1. We are using yellow squares for males\n",
    "2. We are using cyan for females.\n",
    "3. We are using black pluses for the support vectors. Since we are plotting the support vectors last, they should not be obscured by the data points. Plus will let the male/female instances show through\n",
    "\n",
    " - NOTE:  The support_vectors_ attribute might give an error if the model didn't converge or if the problem is not linearly separable. To try to get it to converge, try adjusting the kernel (more on kernels in the Lab 3 Project) or tuning hyperparameters (more on this below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train a Neural Network (NN) Model\n",
    "\n",
    "Now we'll use the NN (Multi Level Perceptron ) model. Again, we will give the neural net as much information as possible and understand that it could overfit on the extra data.\n",
    "\n",
    "We have some hyper parameters that we can adjust. For the other models we just let them run with their defaults. Here we are going to use 3 hidden layers and change up the solver to one that is more likely to give good results for a small data set.\n",
    "\n",
    "Train a neural network model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and evaluate Neural Network model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 5:\n",
    "\n",
    "    How well did each model perform?\n",
    "    Are there any surprising results?\n",
    "    Why might one model outperform the others?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6. Final Thoughts & Insights\n",
    "6.1 Summarize Findings\n",
    "\n",
    "**What indicators are strong predictors of gender?**\n",
    "\n",
    "Based on the comprehensive analysis of the Howell dataset, here are the key findings:\n",
    "\n",
    "**Strong Predictors (in order of importance):**\n",
    "\n",
    "1. **Height**: The strongest single predictor of gender\n",
    "   - Achieved 71% accuracy using height alone\n",
    "   - Clear biological dimorphism between male and female heights\n",
    "   - Simple, interpretable relationship\n",
    "\n",
    "2. **Height + Weight Combined**: Most robust predictor set\n",
    "   - SVM achieved 77% accuracy using both features\n",
    "   - Decision Tree maintained 71% accuracy with both features\n",
    "   - Captures complementary aspects of physical dimorphism\n",
    "\n",
    "3. **Weight**: Moderate predictor on its own\n",
    "   - Less reliable than height as a standalone predictor\n",
    "   - More variability due to lifestyle factors\n",
    "\n",
    "**Model Performance Analysis:**\n",
    "\n",
    "1. **Decision Tree**: \n",
    "   - Training accuracy: 100% (clear overfitting)\n",
    "   - Test accuracy: 71% \n",
    "   - Excellent interpretability but prone to overfitting\n",
    "\n",
    "2. **Support Vector Machine (SVM)**:\n",
    "   - Best overall performance: 77% test accuracy\n",
    "   - More robust to overfitting\n",
    "   - Good balance of precision and recall\n",
    "\n",
    "3. **Neural Network**:\n",
    "   - Poor performance: 53% accuracy (worse than random guessing)\n",
    "   - Failed to converge properly on this small dataset\n",
    "   - Overly complex for the available data size\n",
    "\n",
    "**Key Insights:**\n",
    "- **Height emerges as the most reliable single predictor** due to consistent sexual dimorphism\n",
    "- **SVM performs best overall**, handling the feature combination more effectively\n",
    "- **Simple models work better** than complex ones for this small dataset (346 adults)\n",
    "- **Overfitting is a major concern** - all models show significant training vs. test performance gaps\n",
    "\n",
    "6.2 Discuss Challenges Faced\n",
    "\n",
    "    Small sample size could limit generalizability.\n",
    "    Missing values (if any) could bias the model.\n",
    "\n",
    "6.3 Next Steps\n",
    "\n",
    "    Test more features (e.g., BMI class).\n",
    "    Try hyperparameter tuning for better results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied-ml-branton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
