{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branton - Project 5 - Ensemble ML, Spiral (Wine)\n",
    "**Author:** Branton Dawson  \n",
    "**Date:** November 19, 2025  \n",
    "**Objective:** Wine Dataset - explore ensemble models, a powerful approach in machine learning that combines multiple models to improve performance\n",
    "\n",
    "**Ensemble methods often outperform individual models by reducing overfitting and improving generalization.**\n",
    "\n",
    "    Boosted Decision Trees – Models train sequentially, with each new tree correcting the errors of the previous one.\n",
    "    Random Forest – Multiple decision trees train in parallel, each on a random subset of the data, and their predictions are averaged.\n",
    "    Voting Classifier (Heterogeneous Models) – Combines different types of models \n",
    "        (e.g., Decision Tree, SVM, and Neural Network) by taking the majority vote or average prediction.\n",
    "    Cross Validation – Divides data into multiple folds to improve the reliability of performance estimates.\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "We will evaluate model performance using the following metrics:\n",
    "\n",
    "   - Accuracy –  The proportion of all predictions that are correct.\n",
    "   - Precision – Proportion of positive predictions that are truly positive.\n",
    "   - Recall – Proportion of actual positives that are correctly predicted.\n",
    "   - F1 Score – Harmonic mean of precision and recall, balancing both.\n",
    "\n",
    "These metrics are especially helpful when working with multiple classes (e.g., low, medium, high), not just binary yes/no predictions.\n",
    "\n",
    "Good models have:\n",
    "\n",
    "- High Test Accuracy – the model predicts well on new, unseen (e.g., test) data.\n",
    "- High Test F1 Score – especially useful  if some classes (categories) have fewer examples than others.\n",
    "- Small Gap between Train and Test accuracy – shows the model is generalizing well (not overfitting or underfitting).\n",
    "- Small Gap between Train and Test F1 score – shows the model is generalizing well (not overfitting or underfitting).\n",
    "\n",
    "Recommendation: See if you can add gap calculations to your results and sort the table by test accuracy to find the best models more efficiently. \n",
    "\n",
    "### We use the Wine Quality Dataset made available by the UCI Machine Learning Repository.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "Links to an external site.\n",
    "Data originally published by:\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.  Import and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Load and Explore the Data\n",
    "### 1.1 Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fixed acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatile acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "citric acid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "residual sugar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chlorides",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "free sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sulphates",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alcohol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f7092779-f0cb-4930-83e1-cc62e0646482",
       "rows": [
        [
         "0",
         "7.4",
         "0.7",
         "0.0",
         "1.9",
         "0.076",
         "11.0",
         "34.0",
         "0.9978",
         "3.51",
         "0.56",
         "9.4",
         "5"
        ],
        [
         "1",
         "7.8",
         "0.88",
         "0.0",
         "2.6",
         "0.098",
         "25.0",
         "67.0",
         "0.9968",
         "3.2",
         "0.68",
         "9.8",
         "5"
        ],
        [
         "2",
         "7.8",
         "0.76",
         "0.04",
         "2.3",
         "0.092",
         "15.0",
         "54.0",
         "0.997",
         "3.26",
         "0.65",
         "9.8",
         "5"
        ],
        [
         "3",
         "11.2",
         "0.28",
         "0.56",
         "1.9",
         "0.075",
         "17.0",
         "60.0",
         "0.998",
         "3.16",
         "0.58",
         "9.8",
         "6"
        ],
        [
         "4",
         "7.4",
         "0.7",
         "0.0",
         "1.9",
         "0.076",
         "11.0",
         "34.0",
         "0.9978",
         "3.51",
         "0.56",
         "9.4",
         "5"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "# The dataset includes 11 physicochemical input variables (features):\n",
    "# ---------------------------------------------------------------\n",
    "# - fixed acidity          mostly tartaric acid\n",
    "# - volatile acidity       mostly acetic acid (vinegar)\n",
    "# - citric acid            can add freshness and flavor\n",
    "# - residual sugar         remaining sugar after fermentation\n",
    "# - chlorides              salt content\n",
    "# - free sulfur dioxide    protects wine from microbes\n",
    "# - total sulfur dioxide   sum of free and bound forms\n",
    "# - density                related to sugar content\n",
    "# - pH                     acidity level (lower = more acidic)\n",
    "# - sulphates              antioxidant and microbial stabilizer\n",
    "# - alcohol                % alcohol by volume\n",
    "\n",
    "# The target variable is:\n",
    "# - quality (integer score from 0 to 10, rated by wine tasters)\n",
    "\n",
    "# We will simplify this target into three categories:\n",
    "#   - low (3–4), medium (5–6), high (7–8) to make classification feasible.\n",
    "#   - we will also make this numeric (we want both for clarity)\n",
    "# The dataset contains 1599 samples and 12 columns (11 features + target)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Prepare the data\n",
    "Includes cleaning, feature engineering, encoding, splitting, helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fixed acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatile acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "citric acid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "residual sugar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chlorides",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "free sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sulphates",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alcohol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "quality_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "quality_numeric",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "be8fd0a4-1b5e-4eaf-98fb-67657668bfa1",
       "rows": [
        [
         "0",
         "7.4",
         "0.7",
         "0.0",
         "1.9",
         "0.076",
         "11.0",
         "34.0",
         "0.9978",
         "3.51",
         "0.56",
         "9.4",
         "5",
         "medium",
         "1"
        ],
        [
         "1",
         "7.8",
         "0.88",
         "0.0",
         "2.6",
         "0.098",
         "25.0",
         "67.0",
         "0.9968",
         "3.2",
         "0.68",
         "9.8",
         "5",
         "medium",
         "1"
        ],
        [
         "2",
         "7.8",
         "0.76",
         "0.04",
         "2.3",
         "0.092",
         "15.0",
         "54.0",
         "0.997",
         "3.26",
         "0.65",
         "9.8",
         "5",
         "medium",
         "1"
        ],
        [
         "3",
         "11.2",
         "0.28",
         "0.56",
         "1.9",
         "0.075",
         "17.0",
         "60.0",
         "0.998",
         "3.16",
         "0.58",
         "9.8",
         "6",
         "medium",
         "1"
        ],
        [
         "4",
         "7.4",
         "0.7",
         "0.0",
         "1.9",
         "0.076",
         "11.0",
         "34.0",
         "0.9978",
         "3.51",
         "0.56",
         "9.4",
         "5",
         "medium",
         "1"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>quality_label</th>\n",
       "      <th>quality_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality quality_label  quality_numeric  \n",
       "0      9.4        5        medium                1  \n",
       "1      9.8        5        medium                1  \n",
       "2      9.8        5        medium                1  \n",
       "3      9.8        6        medium                1  \n",
       "4      9.4        5        medium                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define helper function that:\n",
    "# Takes one input, the quality (which we will temporarily name q while in the function)\n",
    "# And returns a string of the quality label (low, medium, high)\n",
    "# This function will be used to create the quality_label column\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "\n",
    "# Then, create a numeric column for modeling: 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numberic' - drop these from the input array\n",
    "# Target: quality_label (the new column we just created)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Split the Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.  Evaluate Model Performance \n",
    "- Option 1. Random Forest (100)     - A strong baseline model using 100 decision trees.\n",
    "- Option 2. Voting (RF + LR + KNN)  - Another mix of different model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n",
      "\n",
      "Voting (RF + LR + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 258   6]\n",
      " [  0  27  16]]\n",
      "Train Accuracy: 0.9132, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.8940, Test F1 Score: 0.8236\n",
      "\n",
      "Voting (RF + LR + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 258   6]\n",
      " [  0  27  16]]\n",
      "Train Accuracy: 0.9132, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.8940, Test F1 Score: 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repos\\applied-ml-branton\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Choose and evaluate two models\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 2. Voting Classifier (RF + LR + KNN)\n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=100)),\n",
    "        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (RF + LR + KNN)\", voting2, X_train, y_train, X_test, y_test, results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n",
      "\n",
      "Random Forest (200, max_depth=10) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 255   9]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9758, Test Accuracy: 0.8812\n",
      "Train F1 Score: 0.9745, Test F1 Score: 0.8596\n",
      "\n",
      "AdaBoost (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  5 240  19]\n",
      " [  0  20  23]]\n",
      "Train Accuracy: 0.8342, Test Accuracy: 0.8250\n",
      "Train F1 Score: 0.8209, Test F1 Score: 0.8158\n",
      "\n",
      "Random Forest (200, max_depth=10) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 255   9]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9758, Test Accuracy: 0.8812\n",
      "Train F1 Score: 0.9745, Test F1 Score: 0.8596\n",
      "\n",
      "AdaBoost (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  5 240  19]\n",
      " [  0  20  23]]\n",
      "Train Accuracy: 0.8342, Test Accuracy: 0.8250\n",
      "Train F1 Score: 0.8209, Test F1 Score: 0.8158\n",
      "\n",
      "AdaBoost (200, lr=0.5) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  2 255   7]\n",
      " [  0  25  18]]\n",
      "Train Accuracy: 0.8397, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.8160, Test F1 Score: 0.8330\n",
      "\n",
      "AdaBoost (200, lr=0.5) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  2 255   7]\n",
      " [  0  25  18]]\n",
      "Train Accuracy: 0.8397, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.8160, Test F1 Score: 0.8330\n",
      "\n",
      "Gradient Boosting (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 247  14]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9601, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9584, Test F1 Score: 0.8411\n",
      "\n",
      "Gradient Boosting (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 247  14]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9601, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9584, Test F1 Score: 0.8411\n",
      "\n",
      "Voting (DT + SVM + NN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 252  12]\n",
      " [  0  21  22]]\n",
      "Train Accuracy: 0.9195, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9017, Test F1 Score: 0.8328\n",
      "\n",
      "Voting (DT + SVM + NN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 252  12]\n",
      " [  0  21  22]]\n",
      "Train Accuracy: 0.9195, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9017, Test F1 Score: 0.8328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repos\\applied-ml-branton\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Voting (RF + LR + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 257   7]\n",
      " [  0  27  16]]\n",
      "Train Accuracy: 0.9148, Test Accuracy: 0.8531\n",
      "Train F1 Score: 0.8966, Test F1 Score: 0.8210\n",
      "\n",
      "Bagging (DT, 100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 252  12]\n",
      " [  0  12  31]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8844\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8655\n",
      "\n",
      "Bagging (DT, 100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 252  12]\n",
      " [  0  12  31]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8844\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8655\n",
      "\n",
      "MLP Classifier Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 257   7]\n",
      " [  0  30  13]]\n",
      "Train Accuracy: 0.8514, Test Accuracy: 0.8438\n",
      "Train F1 Score: 0.8141, Test F1 Score: 0.8073\n",
      "\n",
      "MLP Classifier Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 257   7]\n",
      " [  0  30  13]]\n",
      "Train Accuracy: 0.8514, Test Accuracy: 0.8438\n",
      "Train F1 Score: 0.8141, Test F1 Score: 0.8073\n"
     ]
    }
   ],
   "source": [
    "# **** DELETE THIS AFTER TESTING ****\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1. Random Forest\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 2. Random Forest (200, max depth=10) \n",
    "evaluate_model(\n",
    "    \"Random Forest (200, max_depth=10)\",\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 3. AdaBoost \n",
    "evaluate_model(\n",
    "    \"AdaBoost (100)\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 4. AdaBoost (200, lr=0.5) \n",
    "evaluate_model(\n",
    "    \"AdaBoost (200, lr=0.5)\",\n",
    "    AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 5. Gradient Boosting\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100)\",\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 6. Voting Classifier (DT, SVM, NN) \n",
    "voting1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"DT\", DecisionTreeClassifier()),\n",
    "        (\"SVM\", SVC(probability=True)),\n",
    "        (\"NN\", MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000)),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (DT + SVM + NN)\", voting1, X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 7. Voting Classifier (RF, LR, KNN) \n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=100)),\n",
    "        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "        (\"KNN\", KNeighborsClassifier()),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "evaluate_model(\n",
    "    \"Voting (RF + LR + KNN)\", voting2, X_train, y_train, X_test, y_test, results\n",
    ")\n",
    "\n",
    "# 8. Bagging \n",
    "evaluate_model(\n",
    "    \"Bagging (DT, 100)\",\n",
    "    BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 9. MLP Classifier \n",
    "evaluate_model(\n",
    "    \"MLP Classifier\",\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Compare Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Train Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Test Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Train F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Test F1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3aba40fc-0044-4ab7-82ef-8e5731b94135",
       "rows": [
        [
         "0",
         "Random Forest (100)",
         "1.0",
         "0.8875",
         "1.0",
         "0.86606"
        ],
        [
         "1",
         "Random Forest (200, max_depth=10)",
         "0.97576",
         "0.88125",
         "0.97448",
         "0.85964"
        ],
        [
         "2",
         "AdaBoost (100)",
         "0.83425",
         "0.825",
         "0.82086",
         "0.8158"
        ],
        [
         "3",
         "AdaBoost (200, lr=0.5)",
         "0.83972",
         "0.85625",
         "0.81596",
         "0.83296"
        ],
        [
         "4",
         "Gradient Boosting (100)",
         "0.96013",
         "0.85625",
         "0.95841",
         "0.84111"
        ],
        [
         "5",
         "Voting (DT + SVM + NN)",
         "0.91947",
         "0.85625",
         "0.90166",
         "0.83279"
        ],
        [
         "6",
         "Voting (RF + LR + KNN)",
         "0.91478",
         "0.85312",
         "0.89661",
         "0.82103"
        ],
        [
         "7",
         "Bagging (DT, 100)",
         "1.0",
         "0.88438",
         "1.0",
         "0.86545"
        ],
        [
         "8",
         "MLP Classifier",
         "0.85145",
         "0.84375",
         "0.81414",
         "0.80732"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (100)</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.88750</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.86606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (200, max_depth=10)</td>\n",
       "      <td>0.97576</td>\n",
       "      <td>0.88125</td>\n",
       "      <td>0.97448</td>\n",
       "      <td>0.85964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost (100)</td>\n",
       "      <td>0.83425</td>\n",
       "      <td>0.82500</td>\n",
       "      <td>0.82086</td>\n",
       "      <td>0.81580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost (200, lr=0.5)</td>\n",
       "      <td>0.83972</td>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.81596</td>\n",
       "      <td>0.83296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting (100)</td>\n",
       "      <td>0.96013</td>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.95841</td>\n",
       "      <td>0.84111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting (DT + SVM + NN)</td>\n",
       "      <td>0.91947</td>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.90166</td>\n",
       "      <td>0.83279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Voting (RF + LR + KNN)</td>\n",
       "      <td>0.91478</td>\n",
       "      <td>0.85312</td>\n",
       "      <td>0.89661</td>\n",
       "      <td>0.82103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bagging (DT, 100)</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.88438</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.86545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.85145</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.81414</td>\n",
       "      <td>0.80732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Train Accuracy  Test Accuracy  Train F1  \\\n",
       "0                Random Forest (100)         1.00000        0.88750   1.00000   \n",
       "1  Random Forest (200, max_depth=10)         0.97576        0.88125   0.97448   \n",
       "2                     AdaBoost (100)         0.83425        0.82500   0.82086   \n",
       "3             AdaBoost (200, lr=0.5)         0.83972        0.85625   0.81596   \n",
       "4            Gradient Boosting (100)         0.96013        0.85625   0.95841   \n",
       "5             Voting (DT + SVM + NN)         0.91947        0.85625   0.90166   \n",
       "6             Voting (RF + LR + KNN)         0.91478        0.85312   0.89661   \n",
       "7                  Bagging (DT, 100)         1.00000        0.88438   1.00000   \n",
       "8                     MLP Classifier         0.85145        0.84375   0.81414   \n",
       "\n",
       "   Test F1  \n",
       "0  0.86606  \n",
       "1  0.85964  \n",
       "2  0.81580  \n",
       "3  0.83296  \n",
       "4  0.84111  \n",
       "5  0.83279  \n",
       "6  0.82103  \n",
       "7  0.86545  \n",
       "8  0.80732  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# print results to 5 decimal places\n",
    "print(\"\\nSummary of All Models:\")\n",
    "display(results_df.round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7. Conclusions and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Basic results for our classification model to predict arm on the spiral data set\n",
    "\n",
    "| Model | Training Features | Acc Train | F1 Train |Acc Test | F1 Test |\n",
    "|:---|:---|:---|:---|:---|:---|\n",
    "|Decision Tree|A,B|100.0|100.0|71.62 | 71.63 |\n",
    "|SVC|A,B|71.58|71.58|70.5|70.42|\n",
    "|MLP|A,B layers (50,25,10) lbfgs|80.06|80.13|77.87|77.91"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied-ml-branton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
